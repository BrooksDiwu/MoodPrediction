{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import unicodedata\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "import sklearn.model_selection as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(filename, encoded=False):\n",
    "    if encoded:\n",
    "        return pd.read_csv(filename, encoding = \"ISO-8859-1\", header=None)\n",
    "    else:\n",
    "        return pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "smileyfaces = [':-)', ':)', ':D', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)']\n",
    "sadfaces = ['>:[', ':-(', ':(', ':-c', ':c', ':-<', ':<', ':-[', ':[', ':{', '=(','=[', 'D:']\n",
    "angryfaces = ['>:(', '(╯°□°)╯︵ ┻━┻']\n",
    "cryingfaces = [\":’-(\", \":’(\"]\n",
    "skepticalfaces = ['>:', '>:/', ':-/', '=/',':L', '=L', ':S', '>.<']\n",
    "noexpressionfaces = [':|', ':-|', '(｀・ω・´)']\n",
    "surprisedfaces = ['>:O', ':-O', ':O', ':-o', ':o', '8O', 'O_O', 'o-o', 'O_o', 'o_O', 'o_o', 'O-O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(wordSeries):\n",
    "    def remove_punctuation(x):\n",
    "        for char in string.punctuation:\n",
    "            x = x.replace(char, ' ')\n",
    "        return x\n",
    "    for smile in smileyfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(smile, ' smileyface '))\n",
    "    for sad in sadfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(sad,' sadface '))\n",
    "    for angry in angryfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(angry, ' angryface '))\n",
    "    for cry in cryingfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(cry, ' cryingface '))\n",
    "    for skeptical in skepticalfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(skeptical, ' skepticalface '))\n",
    "    for noexp in noexpressionfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(noexp, ' noexpressionfaces '))\n",
    "    for surprised in surprisedfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(surprised, ' surprisedface '))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.replace('...', ' dotdotdot '))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.replace('!', ' exclamatory '))\n",
    "    wordSeries = wordSeries.apply(lambda x: remove_punctuation(x))\n",
    "    wordSeries = wordSeries.apply(lambda x: ''.join([i for i in x if not i.isdigit()]))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.lower())\n",
    "    #wordSeries = wordSeries.apply(lambda x: x.replace('http', ' '))\n",
    "    wordSeries = wordSeries.apply(lambda x: ' '.join( [w for w in x.split() if len(w)>1] ))\n",
    "    return wordSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanTextU(wordSeries):\n",
    "    tbl = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                          if unicodedata.category(chr(i)).startswith('P'))\n",
    "    def remove_punctuation(text):\n",
    "        return text.translate(tbl)\n",
    "    for smile in smileyfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(smile, ' smileyface '))\n",
    "    for sad in sadfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(sad,' sadface '))\n",
    "    for angry in angryfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(angry, ' angryface '))\n",
    "    for cry in cryingfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(cry, ' cryingface '))\n",
    "    for skeptical in skepticalfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(skeptical, ' skepticalface '))\n",
    "    for noexp in noexpressionfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(noexp, ' noexpressionfaces '))\n",
    "    for surprised in surprisedfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(surprised, ' surprisedface '))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.replace('...', ' dotdotdot '))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.replace('!', ' exclamatory '))\n",
    "    wordSeries = wordSeries.apply(lambda x: remove_punctuation(x))\n",
    "    wordSeries = wordSeries.apply(lambda x: ''.join([i for i in x if not i.isdigit()]))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.lower())\n",
    "    wordSeries = wordSeries.apply(lambda x: x.replace('<br >',' '))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.replace('<br>',' '))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.replace('`',''))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.replace(' id ', ' '))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.replace(' im ', ' '))\n",
    "    #wordSeries = wordSeries.apply(lambda x: x.replace('http', ' '))\n",
    "    wordSeries = wordSeries.apply(lambda x: ' '.join( [w for w in x.split() if len(w)>1] ))\n",
    "    return wordSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(documents, unicode):\n",
    "    if unicode:\n",
    "        documents = cleanTextU(documents)\n",
    "    else:\n",
    "        documents = cleanText(documents)\n",
    "    docs = [word_tokenize(content) for content in documents]\n",
    "    stopwords_=set(stopwords.words('english'))\n",
    "    def filter_tokens(sent):\n",
    "        return([w for w in sent if not w in stopwords_])\n",
    "    docs=list(map(filter_tokens,docs))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    docs_lemma = [[lemmatizer.lemmatize(word) for word in words] for words in docs]\n",
    "    return docs_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTFIDF(data, contentCol, encoded = False):\n",
    "    data['Tokens'] = tokenize(data[contentCol], encoded)\n",
    "    data['Tokens'] = data['Tokens'].apply(lambda x: ' '.join(x))\n",
    "    corpus = [row for row in data['Tokens']]\n",
    "    tfidf = TfidfVectorizer()\n",
    "    document_tfidf_matrix = tfidf.fit_transform(corpus)\n",
    "    return tfidf, document_tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCorpus(data):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabel(data, label):\n",
    "    return data[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRegressor(X,y):\n",
    "    lg = LogisticRegression(max_iter = 1000)\n",
    "    lg.fit(X,y)\n",
    "    return lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def useTFIDF(data, contentCol, tfidf, encoded = False):\n",
    "    data['Tokens'] = tokenize(data[contentCol], encoded)\n",
    "    data['Tokens'] = data['Tokens'].apply(lambda x: ' '.join(x))\n",
    "    corpus = [row for row in data['Tokens']]\n",
    "    document_tfidf_matrix = tfidf.transform(corpus)\n",
    "    return document_tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPolarity(data, model, X):\n",
    "    data['polarity'] = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitPositiveNegative(data):\n",
    "    positiveS = ['enthusiasm', 'neutral', 'surprise', 'love', 'fun', 'happiness', 'relief']\n",
    "    negativeS = ['empty', 'sadness', 'neutral', 'worry', 'hate', 'boredom', 'anger']\n",
    "    dataP = data[data['sentiment'].isin(positiveS)]\n",
    "    dataN = data[data['sentiment'].isin(negativeS)]\n",
    "    dataP['Tokens'] = tokenize(dataP['content'], False)\n",
    "    dataN['Tokens'] = tokenize(dataN['content'], False)\n",
    "    return dataP, dataN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    tokens = tokenize(X, False)\n",
    "    tokens = [' '.join(x) for x in tokens]\n",
    "    corpus = [row for row in tokens]\n",
    "    polarityMTX = tfidfPolar.transform(corpus)\n",
    "    preds = polarityClassifier.predict(polarityMTX)\n",
    "    moodPredictions = []\n",
    "    for idx in range(len(preds)):\n",
    "        if preds[idx] == 4:\n",
    "            mtx = tfidfPositive.transform([tokens[idx]])\n",
    "            moodPredictions.append(positiveClassifier.predict(mtx)[0])\n",
    "        else:\n",
    "            mtx = tfidfNegative.transform([tokens[idx]])\n",
    "            moodPredictions.append(negativeClassifier.predict(mtx)[0])\n",
    "    return moodPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(X, y):\n",
    "    count = 0\n",
    "    preds = predict(X)\n",
    "    for idx in range(len(y)):\n",
    "        if y[idx] == preds[idx]:\n",
    "            count+=1\n",
    "    return count/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.504475"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(dataSentiment['content'], dataSentiment['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worry', 'neutral']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attempt = pd.DataFrame({'content': [\"I had a horrible day today. It was raining and I hated it.\",\n",
    "                                   \"I found a hundred dollar bill and now I'm rich!\"]}, )\n",
    "predict(attempt['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPolar = readCSV('text_polarity.csv',True)\n",
    "tfidfPolar, Xpolar = createTFIDF(dataPolar, 5, True)\n",
    "ypolar = getLabel(dataPolar, 0)\n",
    "polarityClassifier = createRegressor(Xpolar, ypolar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brooks/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/brooks/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/Users/brooks/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/brooks/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "dataSentiment = readCSV('text_emotion.csv')\n",
    "dataPositive, dataNegative = splitPositiveNegative(dataSentiment)\n",
    "tfidfPositive, Xpositive = createTFIDF(dataPositive, 'content', False)\n",
    "tfidfNegative, Xnegative = createTFIDF(dataNegative, 'content', False)\n",
    "yPositive = getLabel(dataPositive, 'sentiment')\n",
    "yNegative = getLabel(dataNegative, 'sentiment')\n",
    "positiveClassifier = createRegressor(Xpositive, yPositive)\n",
    "negativeClassifier = createRegressor(Xnegative, yNegative)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
