{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import unicodedata\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "import sklearn.model_selection as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "smileyfaces = [':-)', ':)', ':D', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)']\n",
    "sadfaces = ['>:[', ':-(', ':(', ':-c', ':c', ':-<', ':<', ':-[', ':[', ':{', '=(','=[', 'D:']\n",
    "angryfaces = ['>:(', '(╯°□°)╯︵ ┻━┻']\n",
    "cryingfaces = [\":’-(\", \":’(\"]\n",
    "skepticalfaces = ['>:', '>:/', ':-/', '=/',':L', '=L', ':S', '>.<']\n",
    "noexpressionfaces = [':|', ':-|', '(｀・ω・´)']\n",
    "surprisedfaces = ['>:O', ':-O', ':O', ':-o', ':o', '8O', 'O_O', 'o-o', 'O_o', 'o_O', 'o_o', 'O-O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanTextU(wordSeries):\n",
    "    tbl = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                          if unicodedata.category(chr(i)).startswith('P'))\n",
    "    def remove_punctuation(text):\n",
    "        return text.translate(tbl)\n",
    "    for smile in smileyfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(smile, ' smileyface '))\n",
    "    for sad in sadfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(sad,' sadface '))\n",
    "    for angry in angryfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(angry, ' angryface '))\n",
    "    for cry in cryingfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(cry, ' cryingface '))\n",
    "    for skeptical in skepticalfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(skeptical, ' skepticalface '))\n",
    "    for noexp in noexpressionfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(noexp, ' noexpressionfaces '))\n",
    "    for surprised in surprisedfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(surprised, ' surprisedface '))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.replace('...', ' dotdotdot '))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.replace('!', ' exclamatory '))\n",
    "    wordSeries = wordSeries.apply(lambda x: remove_punctuation(x))\n",
    "    wordSeries = wordSeries.apply(lambda x: ''.join([i for i in x if not i.isdigit()]))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.lower())\n",
    "    wordSeries = wordSeries.apply(lambda x: x.replace('<br >',' '))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.replace('<br>',' '))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.replace('`',''))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.replace(' id ', ' '))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.replace(' im ', ' '))\n",
    "    #wordSeries = wordSeries.apply(lambda x: x.replace('http', ' '))\n",
    "    wordSeries = wordSeries.apply(lambda x: ' '.join( [w for w in x.split() if len(w)>1] ))\n",
    "    return wordSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(wordSeries):\n",
    "    def remove_punctuation(x):\n",
    "        for char in string.punctuation:\n",
    "            x = x.replace(char, ' ')\n",
    "        return x\n",
    "    for smile in smileyfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(smile, ' smileyface '))\n",
    "    for sad in sadfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(sad,' sadface '))\n",
    "    for angry in angryfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(angry, ' angryface '))\n",
    "    for cry in cryingfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(cry, ' cryingface '))\n",
    "    for skeptical in skepticalfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(skeptical, ' skepticalface '))\n",
    "    for noexp in noexpressionfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(noexp, ' noexpressionfaces '))\n",
    "    for surprised in surprisedfaces:\n",
    "        wordSeries = wordSeries.apply(lambda x: x.replace(surprised, ' surprisedface '))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.replace('...', ' dotdotdot '))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.replace('!', ' exclamatory '))\n",
    "    wordSeries = wordSeries.apply(lambda x: remove_punctuation(x))\n",
    "    wordSeries = wordSeries.apply(lambda x: ''.join([i for i in x if not i.isdigit()]))\n",
    "    wordSeries = wordSeries.apply(lambda x: x.lower())\n",
    "    #wordSeries = wordSeries.apply(lambda x: x.replace('http', ' '))\n",
    "    wordSeries = wordSeries.apply(lambda x: ' '.join( [w for w in x.split() if len(w)>1] ))\n",
    "    return wordSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "def tokenize(documents, unicode):\n",
    "    if unicode:\n",
    "        documents = cleanTextU(documents)\n",
    "    else:\n",
    "        documents = cleanText(documents)\n",
    "    docs = [word_tokenize(content) for content in documents]\n",
    "    stopwords_=set(stopwords.words('english'))\n",
    "    def filter_tokens(sent):\n",
    "        return([w for w in sent if not w in stopwords_])\n",
    "    docs=list(map(filter_tokens,docs))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    docs_lemma = [[lemmatizer.lemmatize(word) for word in words] for words in docs]\n",
    "    return docs_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPN = pd.read_csv('text_polarity.csv', encoding = \"ISO-8859-1\", header=None)\n",
    "dataS = pd.read_csv('text_emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataPN.drop(dataPN.index[400000:1200000], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPN[0] = dataPN[0].apply(lambda x: 1 if x == 4 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPN['Tokens'] = tokenize(dataPN[5], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPN['Tokens'] = dataPN['Tokens'].apply(lambda x: ' '.join(x))\n",
    "corpus = [row for row in dataPN['Tokens']]\n",
    "tfidf = TfidfVectorizer()\n",
    "document_tfidf_matrix = tfidf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = document_tfidf_matrix\n",
    "y = dataPN[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-df49c8ba22d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression(max_iter = 800)\n",
    "lg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataS['Tokens'] = tokenize(dataS['content'], False)\n",
    "dataS['tokenJ'] = dataS['Tokens'].apply(lambda x: ' '.join(x))\n",
    "corpusS = [row for row in dataS['tokenJ']]\n",
    "document_tfidf_matrixS = tfidf.transform(corpusS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<40000x436686 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 306344 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_tfidf_matrixS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = document_tfidf_matrixS\n",
    "ys = dataS['sentiment']\n",
    "#X_train, X_test, y_train, y_test = train_test_split(Xs, ys, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.predict(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataS['polarity'] = lg.predict(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveS = ['enthusiasm', 'neutral', 'surprise', 'love', 'fun', 'happiness', 'relief']\n",
    "negativeS = ['empty', 'sadness', 'neutral', 'worry', 'hate', 'boredom', 'anger']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataP = dataS[dataS['sentiment'].isin(positiveS)]\n",
    "dataN = dataS[dataS['sentiment'].isin(negativeS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brooks/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/brooks/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dataP['Tokens'] = tokenize(dataP['content'], False)\n",
    "dataN['Tokens'] = tokenize(dataN['content'], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brooks/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dataP['tokenJ'] = dataP['Tokens'].apply(lambda x: ' '.join(x))\n",
    "corpusP = [row for row in dataP['tokenJ']]\n",
    "tfidfP = TfidfVectorizer()\n",
    "Xp = tfidfP.fit_transform(corpusP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brooks/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dataN['tokenJ'] = dataN['Tokens'].apply(lambda x: ' '.join(x))\n",
    "corpusN = [row for row in dataN['tokenJ']]\n",
    "tfidfN = TfidfVectorizer()\n",
    "Xn = tfidfN.fit_transform(corpusN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "yn = dataN['sentiment']\n",
    "yp = dataP['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=300,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgP = LogisticRegression(max_iter = 300)\n",
    "lgN = LogisticRegression(max_iter = 300)\n",
    "lgP.fit(Xp, yp)\n",
    "lgN.fit(Xn, yn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "testP = dataS[dataS['polarity'] == 1]\n",
    "testN = dataS[dataS['polarity'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brooks/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/brooks/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "testP['Tokens'] = tokenize(testP['content'], False)\n",
    "testN['Tokens'] = tokenize(testN['content'], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brooks/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "testP['tokenJ'] = testP['Tokens'].apply(lambda x: ' '.join(x))\n",
    "corpusP = [row for row in testP['tokenJ']]\n",
    "Xtestp = tfidfP.transform(corpusP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brooks/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "testN['tokenJ'] = testN['Tokens'].apply(lambda x: ' '.join(x))\n",
    "corpusN = [row for row in testN['tokenJ']]\n",
    "Xtestn = tfidfN.transform(corpusN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytestp = testP['sentiment']\n",
    "ytestn = testN['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47528850367629155"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgP.score(Xtestp, ytestp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.528284437137132"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgN.score(Xtestn, ytestn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopN(n, reg, X, y, moods):\n",
    "    probs = reg.predict_proba(X)\n",
    "    topN = []\n",
    "    for prob in probs:\n",
    "        best_N = list(reversed(np.argsort(prob)))[:n]\n",
    "        topN.append(best_N)\n",
    "    topN = np.array(topN)\n",
    "    mood = np.array(sorted(moods))\n",
    "    topNpred = mood[topN]\n",
    "    return topNpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore(X, y):\n",
    "    count = 0\n",
    "    for idx in range(len(y)):\n",
    "        if np.array(y)[idx] in X[idx]:\n",
    "            count+=1\n",
    "    return count/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7205044553732288"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XpredsP = getTopN(3, lgP, Xtestp, ytestp, positiveS)\n",
    "getScore(XpredsP, ytestp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7363201972974361"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XpredsN = getTopN(3, lgN, Xtestn, ytestn, negativeS)\n",
    "getScore(XpredsN, ytestn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
